{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"script.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yULmqMYxLUDE","executionInfo":{"status":"ok","timestamp":1623742419860,"user_tz":-120,"elapsed":53272,"user":{"displayName":"GUILLEM MORENO","photoUrl":"","userId":"12453155340468470222"}},"outputId":"23f52a03-f331-435a-8c17-94dc824b9aa1"},"source":["#IMPORTS\n","import numpy as np \n","from matplotlib import pyplot as plt\n","import torch\n","from torchvision import datasets, transforms\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from skimage.util import random_noise\n","from skimage.filters import gaussian\n","from skimage.io import imread, imsave\n","from torchvision.utils import make_grid\n","import imageio\n","from IPython.display import Image as Im\n","import os\n","from PIL import Image\n","from google.colab import drive\n","import scipy.io as sio\n","\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","#GLOBAL VARIABLES (paths)\n","workspace_path = \"/content/drive/My Drive/DeepLearning_2021/Project/\"\n","dataset_path = \"arcDataset/\"\n","house_path = \"house/\"\n","houseBigData_path = \"house_bigdata/\"\n","building_old_path = \"building_old/\"\n","building_normal_path = \"building_normal/\"\n","building_modern_path = \"building_modern/\"\n","church_historical_path = \"church_historical/\"\n","results_path = \"results/\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ONUKCKgDLUDJ"},"source":["selected_style = house_path  # Which of our classes are we going to work with?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9ObqkXyUvn_"},"source":["#MAKING OUR OWN CLASS LOADER\n","class BuildingsDB(torch.utils.data.Dataset):\n","    # Initialization method for the dataset\n","    def __init__(self,dataDir = workspace_path+dataset_path+selected_style+'data.mat', transform = None):\n","        mat_loaded = sio.loadmat(dataDir)\n","        self.data = mat_loaded[\"data\"]\n","        self.transform = transform\n","\n","    # What to do to load a single item in the dataset ( read image. No labels)  \n","    def __getitem__(self, index):\n","        data = self.data[index,:,:,:]   \n","        data = Image.fromarray(data,mode='RGB')\n","        # Apply a trasnformaiton to the image if it is indicated in the initalizer\n","        if self.transform is not None : \n","            data = self.transform(data)\n","        \n","        # return the image and the label\n","        return data\n","\n","    # Return the number of images\n","    def __len__(self):\n","        return self.data.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqndcjBELUDL"},"source":["#INITIALIZING OUR TRAIN DATA LOADER\n","\n","# transformation: to tensor\n","tr = transforms.Compose([\n","        transforms.ToTensor(), \n","        ])\n","\n","# database: a \".mat\" file for a specific style\n","database = BuildingsDB(workspace_path+dataset_path+selected_style+\"data.mat\", transform=tr)\n","\n","# creating the dataloader from the previous database\n","data_loader = torch.utils.data.DataLoader(dataset=database,\n","                                           batch_size=128, \n","                                           shuffle=True)\n","\n","# Mini-batch images loading (just to see if everything is correct)\n","images = next(iter(data_loader))\n","for i in range(5):\n","    image = images[i,:,:,:]\n","    print(image.shape)\n","    plt.imshow(image.permute(1,2,0).squeeze().numpy())\n","    plt.axis('off')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KH5nb_gRLUDM","executionInfo":{"status":"ok","timestamp":1623742444964,"user_tz":-120,"elapsed":579,"user":{"displayName":"GUILLEM MORENO","photoUrl":"","userId":"12453155340468470222"}}},"source":["#DEFINITION FOR OUR LAYERS\n","\n","# Convolution + BatchNormnalization + ReLU block for the encoder\n","class ConvBNReLU(nn.Module):\n","    def __init__(self,in_channels, out_channels, pooling=False):\n","        super(ConvBNReLU, self).__init__()\n","        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=3,\n","                              padding = 1)\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        self.pool = None\n","        if(pooling):\n","            self.pool = nn.AvgPool2d(2,2)\n","\n","    def forward(self,x):\n","        if(self.pool):\n","            out = self.pool(x)\n","        else:\n","            out = x\n","        out = self.relu(self.bn(self.conv(out)))   \n","        return out\n","\n","#  BatchNormalization + ReLU block + Convolution for the decoder\n","class BNReLUConv(nn.Module):\n","    def __init__(self,in_channels, out_channels, pooling=False):\n","        super(BNReLUConv, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=3,\n","                              padding = 1)\n","\n","        self.pool = None\n","        if(pooling):\n","            self.pool = nn.UpsamplingNearest2d(scale_factor=2)\n","\n","    def forward(self,x):\n","        out = self.relu(self.bn(x))\n","        if(self.pool):\n","            out = self.pool(out)\n","        out = self.conv(out)\n","        return out"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXg8GO_ELUDN","executionInfo":{"status":"ok","timestamp":1623742445564,"user_tz":-120,"elapsed":7,"user":{"displayName":"GUILLEM MORENO","photoUrl":"","userId":"12453155340468470222"}}},"source":["# ENCODER / DECODER DEFINITION\n","#(will be used on the discriminator/generator respectively)\n","\n","# 3 Conv-BN-ReLU blocks and fully-connected layer\n","class Encoder(nn.Module):\n","    def __init__(self,out_features,base_channels=16):\n","        super(Encoder, self).__init__()\n","        self.layer1 = ConvBNReLU(3,base_channels,pooling=False)\n","        self.layer2 = ConvBNReLU(base_channels,base_channels*2,pooling=True)\n","        self.layer3 = ConvBNReLU(base_channels*2,base_channels*4,pooling=True)\n","        self.fc = nn.Linear(32*32*base_channels*4,out_features)\n","  \n","    def forward(self,x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        return self.fc(out.view(x.shape[0],-1))\n","    \n","# 3 BN-ReLU-Conv blocks \n","class Decoder(nn.Module):\n","    def __init__(self,out_features,base_channels=16):\n","        super(Decoder, self).__init__()\n","        self.base_channels = base_channels\n","        self.fc = nn.Linear(out_features,32*32*base_channels*4)\n","        self.layer3 = BNReLUConv(base_channels*4,base_channels*2,pooling=True)\n","        self.layer2 = BNReLUConv(base_channels*2,base_channels,pooling=True)\n","        self.layer1 = BNReLUConv(base_channels,3,pooling=False)\n","  \n","    def forward(self,x):\n","        out = self.fc(x)\n","        out = out.view(x.shape[0],self.base_channels*4,32,32)\n","        out = self.layer3(out)\n","        out = self.layer2(out)\n","        out = self.layer1(out)\n","        return torch.sigmoid(out)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"os4gtIXfLUDO","executionInfo":{"status":"ok","timestamp":1623742446323,"user_tz":-120,"elapsed":4,"user":{"displayName":"GUILLEM MORENO","photoUrl":"","userId":"12453155340468470222"}}},"source":["# DISCRIMINATOR / GENERATOR DEFINITION\n","\n","# Discriminator similar to VAE encoder\n","class Discriminator(nn.Module):\n","    def __init__(self, base_channels=16):\n","        super(Discriminator, self).__init__()\n","        # last fully connected layer acts as a a binary classifier\n","        self.classifier = Encoder(3,base_channels)\n","\n","    # Forward pass obtaining the discriminator probability\n","    def forward(self,x):\n","        out = self.classifier(x)\n","        # use sigmoid to get the real/fake image probability\n","        return torch.sigmoid(out)\n","\n","# Generator is defined as VAE decoder\n","class Generator(nn.Module):\n","    def __init__(self,in_features,base_channels=16):\n","        super(Generator, self).__init__()\n","        self.base_channels = base_channels\n","        self.in_features = in_features\n","        self.decoder = Decoder(in_features,base_channels)\n","\n","    # Generate an image from vector z\n","    def forward(self,z):\n","        return torch.sigmoid(self.decoder(z))\n","\n","    # Sample a set of images from random vectors z\n","    def sample(self,n_samples=128,device='cpu'):\n","        samples_unit_normal = torch.randn((n_samples,self.in_features)).to(device)\n","        return self.decoder(samples_unit_normal)\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"bibP5frJLUDQ","executionInfo":{"status":"ok","timestamp":1623742447190,"user_tz":-120,"elapsed":5,"user":{"displayName":"GUILLEM MORENO","photoUrl":"","userId":"12453155340468470222"}}},"source":["# GAN TRAIN FUNCTION\n","def train_GAN(gen, disc,  train_loader, optimizer_gen, optim_disc,\n","              num_epochs=10, model_name='gan_architecture.ckpt', device='cpu'):\n","    gen = gen.to(device)\n","    gen.train() # Set the generator in train mode\n","    disc = disc.to(device)\n","    disc.train() # Set the discriminator in train mode\n","\n","    total_step = len(train_loader)\n","\n","    #Initializing arrays to return\n","    gen_losses_list = []\n","    disc_losses_list = []\n","    gen_mse_losses_list = []\n","\n","    criterion = nn.MSELoss()  # This one will be the MSE loss between fake and real images\n","\n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        \n","        disc_loss_avg = 0\n","        gen_loss_avg = 0\n","        gen_mse_loss_avg = 0\n","\n","        nBatches = 0\n","        update_generator = True  # Learning on only one model at each epoch\n","\n","        # Iterate the dataset\n","        for i, real_images in enumerate(train_loader):\n","            # Get batch of samples and labels\n","            real_images = real_images.to(device)\n","            n_images = real_images.shape[0]\n","\n","            # Forward pass\n","            # Generate random images with the generator\n","            fake_images = gen.sample(n_images,device=device)\n","\n","            # Use the discriminator to obtain the probabilties for real and generate imee\n","            prob_real = disc(real_images)\n","            prob_fake = disc(fake_images)\n","            \n","            # Generator loss\n","            gen_loss = -torch.log(prob_fake).mean()\n","            # Discriminator loss\n","            disc_loss = -0.5*(torch.log(prob_real) + torch.log(1-prob_fake)).mean()\n","            #MSE Loss fake images vs real images\n","            gen_mse_loss = criterion(fake_images,real_images)\n","            \n","            # We are going to update the discriminator and generator parameters alternatively at each iteration\n","\n","            if(update_generator):\n","                # Optimize generator\n","                # Backward and optimize\n","                optimizer_gen.zero_grad()\n","                gen_loss.backward() # Necessary to not erase intermediate variables needed for computing disc_loss gradient\n","                optimizer_gen.step()\n","                update_generator = False\n","            else:        \n","                # Optimize discriminator\n","                # Backward and optimize\n","                optimizer_disc.zero_grad()\n","                disc_loss.backward()\n","                optimizer_disc.step()\n","                update_generator = True\n","            \n","            #Updating loss\n","            disc_loss_avg += disc_loss.cpu().item()\n","            gen_loss_avg += gen_loss.cpu().item()\n","            gen_mse_loss_avg += gen_mse_loss.cpu().item()\n","\n","            nBatches+=1\n","\n","        if (epoch+1) % 10 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}, Gen. MSE Loss: {:.4f}' \n","                    .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches, gen_mse_loss_avg / nBatches))\n","        \n","        # Save model\n","        gen_losses_list.append(gen_loss_avg / nBatches)\n","        disc_losses_list.append(disc_loss_avg / nBatches)\n","        gen_mse_losses_list.append(gen_mse_loss_avg / nBatches)\n","        torch.save(gen.state_dict(), workspace_path+results_path+ '/' + model_name)\n","\n","        #This part will only be executed for every 100 epochs  \n","        if epoch%100!=0:\n","            continue\n","        \n","        # Creating a grid of 4x4 sample images generated from our generator\n","        x_gen = gen.sample(n_samples=16,device=device)\n","        image_grid = make_grid(x_gen.cpu(),nrow=4,padding=1)\n","        plt.figure(figsize=(8,8))\n","        plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n","        plt.show()\n","\n","        # This part will only be executed at the last epoch\n","        if epoch != num_epochs-1:\n","            continue\n","\n","        # Creating a .gif with 50 interpolations between two Z random vectors \n","        # and saving it    \n","        n_samples = 16\n","        n_iterpolations =50\n","\n","        z_init = torch.randn((n_samples,gen.in_features)).to(device)\n","        z_final = torch.randn((n_samples,gen.in_features)).to(device)\n","\n","        interpolation_images = []\n","        for interp in range(0,n_iterpolations):\n","            interp_0_1 = float(interp) / (n_iterpolations-1)\n","            z = z_init*interp_0_1 + z_final*(1-interp_0_1)\n","            x_rec = gen.decoder(z.to(device))\n","            image_grid = make_grid(x_rec.cpu(),nrow=4,padding=1)\n","            image_grid = image_grid.permute(1,2,0).detach().numpy()\n","\n","            interpolation_images.append((image_grid*255.0).astype(np.uint8))\n","        \n","        interpolation_images += interpolation_images[::-1]\n","\n","        imname = workspace_path+results_path+'/gan_interpolation_churches_historical.gif'\n","        imageio.mimsave(imname, interpolation_images, fps=25)\n","\n","    return gen_losses_list, disc_losses_list, gen_mse_losses_list"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3QggGr7ALUDS"},"source":["# TRAINING\n","\n","# Define Geneartor and Discriminator networks\n","gan_gen = Generator(32) \n","gan_disc = Discriminator()\n","\n","#Initialize independent optimizer for both networks\n","learning_rate = .0004\n","optimizer_gen = torch.optim.Adam(gan_gen.parameters(),lr = learning_rate, betas=(0.2,0.5), weight_decay=1e-5)\n","learning_rate = .00001\n","optimizer_disc = torch.optim.Adam(gan_disc.parameters(),lr = learning_rate, betas=(0.2,0.5), weight_decay=1e-5)\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","# Train the GAN\n","gen_loss_list, disc_loss_list, gen_mse_loss_list = train_GAN(gan_gen,gan_disc, data_loader, optimizer_gen, optimizer_disc,\n","                      num_epochs=20000, model_name='churches_historical.ckpt', device=device)\n","\n","#Plotting the loss for each epoch\n","plt.plot(gen_loss_list, color=\"r\", label=\"generator\")\n","plt.plot(disc_loss_list, color=\"b\", label=\"discriminator\")\n","plt.legend()\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","#Plotting the mse loss for the generator (between real and fake images) for each epoch\n","plt.plot(gen_mse_loss_list)\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"MSE Loss (fake vs. real images)\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6BTg8COMLUDT"},"source":["#LOADING A SAVED MODEL AND PLOTTING 4X4 SAMPLE IMAGES\n","\n","gan_gen = Generator(32)\n","gan_gen.load_state_dict(torch.load(workspace_path+results_path+\"house_20000ep.ckpt\",map_location='cuda:0'))\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","x_gen = gan_gen.sample(n_samples=16,device=\"cpu\")\n","\n","\n","image_grid = make_grid(x_gen.cpu(),nrow=4,padding=1)\n","plt.figure(figsize=(8,8))\n","plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qhyW_HnJuOG"},"source":[""],"execution_count":null,"outputs":[]}]}